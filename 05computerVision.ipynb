{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq2o9EST11yp"
   },
   "source": [
    "# Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iemMW2yH1XIs"
   },
   "source": [
    "#### Welcome to this exercise which introduces Computer Vision!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWmnjDZB2gxZ"
   },
   "source": [
    "<img style=\"float:right;\" src=\"./img/pinhole_model.png\" width= 50% />\n",
    "\n",
    "<br>\n",
    "While photogrammetry has over 100 years of tradition, over the past several years, advances in technology has seen the application of Computer Vision applied in the geospatial domain.\n",
    "<br> <br>\n",
    "\n",
    "\n",
    "Newer technologies often come with their own jargon (terms, definitions and language). This exercise is not meant to be exhaustive but serves as a gentle introduction to the concepts and potential of Computer Vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lBqbY1r2g1h"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> <strong> Lets first define the core difference between these two methods. </strong>  <br> <br>\n",
    "\n",
    "**Computer Vision**: interpretation and understanding of visual data often involving real-time decision-making by machines. Enable machines to interpret and understand visual data. Medical imaging and autonomous navigation|<br><br>\n",
    "**Photogrammetry**: reconstruct 3D structures and spatial relationships. Accurately measure and reconstruct the three-dimensional shape. Remote sensing and mapping.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order for realise the goal of Computer Vision it is often necessary to harvest 3D data from imagery**. While this is also the aim of photogrammetry; the processes differ slightly.he result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Aspect|Traditional Photogrammetry|Computer Vision|\n",
    "|---|---|---|\n",
    "|Stereo|Primarily relies on **_stereo matching_** to create 3D models|Combines stereo vision with **_advanced techniques_** like Structure from Motion Multi-view Stereo (SfM-MVS) and SLAM (Simultaneous Localization and Mapping)|\n",
    "|Calibration|**_Precise sensor calibration_** for accurate results|May involve more **automated_** calibration procedures|\n",
    "|Processing Speed|Time-consuming manual processes|Often performs real-time or **_near-real-time processing_** thanks to powerful hardware and **_optimized algorithms_**.|\n",
    "|Data Volume|Deals with smaller datasets of images.|Analyzes large datasets of images, videos, and 3D point clouds.|\n",
    "|Data Availability|Data acquisition and processing may be costly and time-consuming.|Access to data is becoming more abundant and affordable, thanks to the proliferation of digital cameras and sensors|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBq0MF5L2g5J"
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "  <strong>REQUIRED!</strong> \n",
    "  \n",
    "You are required to insert your outputs and any comment into this document. The document you submit should therefore contain the existing text in addition   \n",
    "    \n",
    "    \n",
    "\n",
    " - Plots and other outputs from exec the code\n",
    "    nks\n",
    " - Discussion of your plots and other outputs as well as conclusions r. \n",
    "    hed.\n",
    " - This should also include any hypotheses and assumptions made as well as factors that may affect your conclusions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmPdx3xY0jmM"
   },
   "outputs": [],
   "source": [
    "!pip3 install open3d\n",
    "\n",
    "#- _ https://github.com/Vedang-101/Structure-From-Motion/blob/main/Python/main.py , https://github.com/Vedang-101/Structure-From-Motion/blob/main/Python/New%20Code/SFM.py _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qLOmuPSmzwTx"
   },
   "outputs": [],
   "source": [
    "#- load the magic\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxXhXIVxvWIh",
    "outputId": "c24ac9c4-b165-4f59-c172-c587850cf492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ov2ly6SsxS3Q"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "dir = os.path.join(\"drive/My Drive/UCTJuly-Nov2023/APG3012S-RSandP/assignments/collinearity/data/sfm/\")#data/sfm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <strong> For this exercise we will harvest 3D data from imagery with Computer Vision. </strong>  \n",
    "<br><br>\n",
    "We will do so in two stages. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1. Structure-from-Motion (SfM)** _(with two images to compare with traditional photogrammetry)_  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.** extend the SfM process with **Multi-view Stereo (MVS)** _(and show how the method accomodates many images)_\n",
    "\n",
    "In the process we will work through such concepts as Feature Matching and Disparity\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this exercise we will work through the well known [(Christoph Strecha's) Fountain-P11 dataset](https://certis.enpc.fr/demos/stereo/Data/Fountain11/index.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_4FeaOlkkLwl"
   },
   "outputs": [],
   "source": [
    "#input_dir = \"./data/sfm/fountain/two/\"\n",
    "input_dir = os.path.join(dir, 'two')\n",
    "#output_dir = \"./data/sfm/fountain/two/result/\"\n",
    "output_dir = os.path.join(dir, 'two', 'result')\n",
    "format_img = \".jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"./data/sfm/two/im2.jpg\" alt=\"Drawing\" style=\"width: 550px;\"/> </td>\n",
    "<td> <img src=\"./data/sfm/two/im4.jpg\" alt=\"Drawing\" style=\"width: 550px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structure-from-Motion (SfM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "6H9f-UnTnzMV"
   },
   "outputs": [],
   "source": [
    "def PointMatchingOpticalFlow(img1, img2, path, save=False):\n",
    "    #matches using optical flow\n",
    "    ffd = cv2.FastFeatureDetector_create()\n",
    "    left_keypoints = ffd.detect(img1, None)\n",
    "    right_keypoints = ffd.detect(img2, None)\n",
    "    left_points = KeyPointsToPoints(left_keypoints)\n",
    "    right_points = np.zeros_like(left_points)\n",
    "\n",
    "    #Checking if images are in greyscale\n",
    "    prevgray = img1\n",
    "    gray = img2\n",
    "    if len(img1.shape) == 3:\n",
    "        prevgray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    right_points, vstatus, verror = cv2.calcOpticalFlowPyrLK(prevgray,gray,left_points,right_points)\n",
    "    #Filterout points with high error\n",
    "    right_points_to_find = []\n",
    "    right_points_to_find_back_index = []\n",
    "    for i in range(0, len(vstatus)):\n",
    "        if(vstatus[i] and verror[i] < 12.0):\n",
    "            right_points_to_find_back_index.append(i)\n",
    "            right_points_to_find.append(right_points[i])\n",
    "        else:\n",
    "            vstatus[i] = 0\n",
    "\n",
    "    found_in_imgpts_j = []\n",
    "    right_points_to_find_flat = np.array(right_points_to_find).reshape(len(right_points_to_find), 2)\n",
    "    right_features = KeyPointsToPoints(right_keypoints)\n",
    "    right_features_flat = right_features.reshape(len(right_features), 2)\n",
    "\n",
    "    #Look around each of point in right image for any features that were detected in its area and make a match\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_L2)\n",
    "    nearest_neighbours = matcher.radiusMatch(right_points_to_find_flat, right_features_flat, 2.0)#THIS IS THE NEW LINE added(Sarthak)\n",
    "    #nearest_neighbours = cv2.BFMatcher().radiusMatch(right_features_flat, right_points_to_find_flat, 2.0)\n",
    "    matches = []\n",
    "    # print(len(nearest_neighbours))\n",
    "\n",
    "    for i in range(0, len(nearest_neighbours)):\n",
    "        _m = None\n",
    "        if len(nearest_neighbours[i]) == 1:\n",
    "            _m = nearest_neighbours[i][0]\n",
    "        elif len(nearest_neighbours[i]) > 1:\n",
    "            if (nearest_neighbours[i][0].distance / nearest_neighbours[i][1].distance) < 0.7:\n",
    "                _m = nearest_neighbours[i][0]\n",
    "            else:\n",
    "                #did not pass ratio test\n",
    "                pass\n",
    "        else:\n",
    "            #no match\n",
    "            pass\n",
    "\n",
    "        #prevent duplicates\n",
    "        if _m != None:\n",
    "            if found_in_imgpts_j.count(_m.trainIdx) == 0:\n",
    "                #back to original indexing of points for <i_idx>\n",
    "                _m.queryIdx = right_points_to_find_back_index[_m.queryIdx]\n",
    "                matches.append(_m)\n",
    "                right_points_to_find_back_index.append(_m.trainIdx) #Added this LINE(Sarthak)\n",
    "\n",
    "    img3 = cv2.drawMatches(img1, left_keypoints, img2, right_keypoints, matches, None)\n",
    "\n",
    "    if save:\n",
    "        #cv2.imwrite(path + \"_x_\"+filename2+\".jpg\", img3) #os.path.join(input_dir, 'im3.jpg'))\n",
    "        cv2.imwrite(os.path.join(path, 'im3_x_im4.jpg'), img3)\n",
    "    return left_keypoints, right_keypoints, matches\n",
    "\n",
    "def KeyPointsToPoints(keypoints):\n",
    "  out = []\n",
    "  for kp in keypoints:\n",
    "    out.append([[kp.pt[0], kp.pt[1]]])\n",
    "  res = np.array(out, dtype=np.float32)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/sfm/result_two/im3_x_im4.jpg\" alt=\"Drawing\" style=\"width: 1000px;\"/> </td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "egD_5M_tl59s"
   },
   "outputs": [],
   "source": [
    "def PairStructureFromMotion():\n",
    "    img1 = cv2.imread(os.path.join(input_dir, 'im3.jpg'))#\"../im3.jpg\")\n",
    "    img2 = cv2.imread(os.path.join(input_dir, 'im4.jpg'))\n",
    "    #kp1, kp2, matches = PointMatchingSURF(img1, img2)\n",
    "    kp1, kp2, matches = PointMatchingOpticalFlow(img1, img2, save=True, path = output_dir)\n",
    "    K = findCalibrationMat()\n",
    "    E = FindEssentialMat(kp1, kp2, matches, K)\n",
    "\n",
    "    P0 = np.float32([[1,0,0,0],\n",
    "                     [0,1,0,0],\n",
    "                     [0,0,1,0]])\n",
    "\n",
    "    P1 = FindPMat(E)\n",
    "    print(P1)\n",
    "\n",
    "    ply = []\n",
    "    error, ply = TraingulatePoints(kp1, kp2, matches, K, P0, P1, img1, ply)\n",
    "    print(\"Mean Error = \", error)\n",
    "\n",
    "    out = PLY(output_dir)\n",
    "    out.insert_header(len(ply), \"fountain\")\n",
    "    for i in range(0,len(ply)):\n",
    "      out.insert_point(ply[i][0],ply[i][1],ply[i][2],ply[i][3],ply[i][4],ply[i][5])\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "7WYjxQzZn3Ak"
   },
   "outputs": [],
   "source": [
    "def PointMatchingSURF(img1, img2, save = False, path = None):\n",
    "    #Match with SURF\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    keypoints1, descriptors1 = surf.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = surf.detectAndCompute(img2, None)\n",
    "\n",
    "    img4 = cv2.drawKeypoints(img1, keypoints1, None)\n",
    "\n",
    "    cv2.imwrite(\"KP.jpg\", img4)\n",
    "    bf = cv2.BFMatcher_create()\n",
    "\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    img3 = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:200], None, flags=2)\n",
    "\n",
    "    if save:\n",
    "        cv2.imwrite('03' + \"_x_\" + '04' +\".jpg\", img3)\n",
    "\n",
    "    return keypoints1, keypoints2,matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>QUESTION! </b>  </div>\n",
    "\n",
    "- **This exercise does not use `Scale-invariant feature transform (SURF)` to match features but executes the `Optical Flow` algorithm** _(you can change the code and see what happens)_.\n",
    "  \n",
    "    **Discuss the difference between these two methods. Mention their strenghts and weaknessess. A note about intellectual property is expected. Your answer cannot be more than 150 words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{ click in this cell and write your answer here }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bJqr3Dl7l6Ab"
   },
   "outputs": [],
   "source": [
    "def findCalibrationMat():\n",
    "    #with open(input_dir+'intrinsic.txt') as f: #os.path.join(input_dir, 'im3.jpg'))\n",
    "    with open(os.path.join(dir, 'intrinsic.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "    return np.array(\n",
    "        [l.strip().split(' ') for l in lines],\n",
    "        dtype=np.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "efrPSg3Gn7CN"
   },
   "outputs": [],
   "source": [
    "def FindEssentialMat(kp1, kp2, matches, K):\n",
    "    imgpts1 = []\n",
    "    imgpts2 = []\n",
    "    for i in range(0, len(matches)):\n",
    "        imgpts1.append([[kp1[matches[i].queryIdx].pt[0], kp1[matches[i].queryIdx].pt[1]]])\n",
    "        imgpts2.append([[kp2[matches[i].trainIdx].pt[0], kp2[matches[i].trainIdx].pt[1]]])\n",
    "\n",
    "    F = cv2.findFundamentalMat(np.array(imgpts1, dtype=np.float32), np.array(imgpts2, dtype=np.float32), method=cv2.FM_RANSAC, ransacReprojThreshold=0.1, confidence=0.99)\n",
    "    E = np.matmul(np.matmul(np.transpose(K), F[0]), K)\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "dMjONpAcoH1E"
   },
   "outputs": [],
   "source": [
    "def checkCoherentRotation(R):\n",
    "    if(math.fabs(np.linalg.det(R))-1.0 > 1e-07):\n",
    "        print(\"Not a coherent rotational Matrix\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Coherent Rotational Matrix found\")\n",
    "        return True\n",
    "\n",
    "def FindPMat(E):\n",
    "    _, u, vt = cv2.SVDecomp(E, flags=cv2.SVD_MODIFY_A)\n",
    "    W = np.float32([[0,-1,0],\n",
    "                    [1,0,0],\n",
    "                    [0,0,1]])\n",
    "    R = np.matmul(np.matmul(u, W), vt)\n",
    "    t = u[:, 2]\n",
    "\n",
    "    P = np.float32([])\n",
    "    if checkCoherentRotation(R):\n",
    "        P = np.float32([[R[0][0], R[0][1], R[0][2], t[0]],\n",
    "                        [R[1][0], R[1][1], R[1][2], t[1]],\n",
    "                        [R[2][0], R[2][1], R[2][2], t[2]]])\n",
    "    else:\n",
    "        P = None\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "07757nREoLK8"
   },
   "outputs": [],
   "source": [
    "def TraingulatePoints(pt_set1, pt_set2, matches, K, P, P1, img1, ply, _current = None):\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    reproj_error = []\n",
    "    for i in range(0, len(matches)):\n",
    "        kp = pt_set1[matches[i].queryIdx].pt\n",
    "        u = np.float32([[[kp[0]], [kp[1]], [1]]])\n",
    "        um = np.matmul(Kinv, u)\n",
    "        u = um[0]\n",
    "\n",
    "        kp1 = pt_set2[matches[i].trainIdx].pt\n",
    "        u1 = np.float32([[[kp1[0]], [kp1[1]], [1]]])\n",
    "        um1 = np.matmul(Kinv, u1)\n",
    "        u1 = um1[0]\n",
    "\n",
    "        #Triangulate\n",
    "        X = LinearLSTriangulation(u, P, u1, P1)\n",
    "\n",
    "        #Calculate reprojection error\n",
    "        X1 = [[X[0][0]],\n",
    "              [X[1][0]],\n",
    "              [X[2][0]],\n",
    "              [1]]\n",
    "        xPt_img = np.matmul(np.matmul(K, P1), X1)\n",
    "\n",
    "        xPt_img_ = np.float32([[xPt_img[0]/xPt_img[2], xPt_img[1]/xPt_img[2]]])\n",
    "        reproj_error.append(np.linalg.norm(xPt_img_-kp1))\n",
    "        reproj_error.append(1.0)\n",
    "\n",
    "        #print(kp[0], kp[1])\n",
    "        bgr = img1[int(kp[1]),int(kp[0])]\n",
    "\n",
    "        if _current is not None:\n",
    "            _current.add_entry((X[0],X[1],X[2]), (kp1[0], kp1[1]))\n",
    "\n",
    "        #x = X[0] y = Y[1] z = X[2]\n",
    "        ply.append([X[0],X[1],X[2],bgr[0],bgr[1],bgr[2]])\n",
    "    me = np.mean(reproj_error)\n",
    "    return me, ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sA8F0iPfoLN0"
   },
   "outputs": [],
   "source": [
    "def LinearLSTriangulation(u, P, u1, P1):\n",
    "    A = np.float32([[u[0]*P[2][0]-P[0][0], u[0]*P[2][1]-P[0][1], u[0]*P[2][2]-P[0][2]],\n",
    "                    [u[1]*P[2][0]-P[1][0], u[1]*P[2][1]-P[1][1], u[1]*P[2][2]-P[1][2]],\n",
    "                    [u1[0]*P1[2][0]-P1[0][0], u1[0]*P1[2][1]-P1[0][1], u1[0]*P1[2][2]-P[0][2]],\n",
    "                    [u1[1]*P1[2][0]-P1[1][0], u1[1]*P1[2][1]-P1[1][1], u1[1]*P1[2][2]-P1[1][2]]])\n",
    "    A = np.reshape(A, [4, 3])\n",
    "    B = np.float32([[-(u[0]*P[2][3]-P[0][3])],\n",
    "                    [-(u[1]*P[2][3]-P[1][3])],\n",
    "                    [-(u1[0]*P1[2][3]-P1[0][3])],\n",
    "                    [-(u1[1]*P1[2][3]-P1[1][3])]])\n",
    "    B = np.reshape(B, [4, 1])\n",
    "    _, X = cv2.solve(A,B,flags=cv2.DECOMP_SVD)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "XvdzWISFmtda"
   },
   "outputs": [],
   "source": [
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "\n",
    "\n",
    "class PLY:\n",
    "\tdef __init__(self, results_dir):\n",
    "\t\tself.dir = results_dir\n",
    "\t\tself.name = None\n",
    "\n",
    "\tdef insert_header(self, point_cloud_size, Name):\n",
    "\t\tself.name = self.dir + Name + '.ply'\n",
    "\n",
    "\t\twith open(self.name, 'wb') as file:\n",
    "\t\t\tfile.write((ply_header % dict(vert_num=point_cloud_size+1)).encode('utf-8'))\n",
    "\t\t\tfile.write('0 0 0 255 0 0\\n'.encode('utf-8'))\n",
    "\n",
    "\tdef insert_point(self, x, y, z, b, g, r):\n",
    "\n",
    "\t\twith open(self.name, 'ab') as file:\n",
    "\t\t\tfile.write((str(x[0]) + ' ').encode('utf-8'))\n",
    "\t\t\tfile.write((str(y[0]) + ' ').encode('utf-8'))\n",
    "\t\t\tfile.write((str(z[0]) + ' ').encode('utf-8'))\n",
    "\t\t\tfile.write((str(r) + ' ').encode('utf-8'))\n",
    "\t\t\tfile.write((str(g) + ' ').encode('utf-8'))\n",
    "\t\t\tfile.write((str(b) + '\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6biHfhb8oLQk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WKoqco8oLTc",
    "outputId": "446cd798-5125-4a76-eca9-fd0c168e6f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherent Rotational Matrix found\n",
      "[[ 0.6421624  -0.06788093 -0.7635572  -0.4350088 ]\n",
      " [ 0.01265835  0.99687475 -0.07797722 -0.02798646]\n",
      " [-0.7664641  -0.04040866 -0.64101475 -0.89999115]]\n",
      "Mean Error =  13976.266673563205\n"
     ]
    }
   ],
   "source": [
    "#- execute\n",
    "PairStructureFromMotion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGsphZNOoLWM"
   },
   "source": [
    "## 2. Multi-view Stereo (MVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-fxjgmzoLZE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e6poPRfoLes"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJJPKqBVoLb9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3IoT2aDoLhk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>TASK / QUESTION! </b>  </div>\n",
    "\n",
    "- **Execute this NoteBook on a series of photographs you have captured yourself** _(no more than 15)_. **This Notebook must therefore contain the output from you own dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqn_w8mroLkd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdzwQCsMoLnN"
   },
   "source": [
    "_images:_\n",
    "\n",
    "- **pinhole model**: https://kornia.readthedocs.io/en/latest/geometry.camera.pinhole.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eLz9rH3oLp8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
